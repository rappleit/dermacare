{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading, preprocessing etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import llama_index\n",
    "import chromadb\n",
    "from chromadb.utils.embedding_functions import OpenCLIPEmbeddingFunction\n",
    "from llama_index.core import SimpleDirectoryReader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialise stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c2dfd1cbe71478ba813e17302590c48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "open_clip_model.safetensors:   0%|          | 0.00/605M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import chromadb\n",
    "\n",
    "client = chromadb.PersistentClient(path=\"my_db\") # persistent DB\n",
    "collection = client.get_or_create_collection(name=\"multimodalDB\", embedding_function= multimodal_ef)\n",
    "\n",
    "multimodal_ef = OpenCLIPEmbeddingFunction() # multimodal embedding function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to add to and query DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add docs to the collection. Can also update and delete. Row-based API coming soon!\n",
    "collection.add(\n",
    "    documents=[\"China\", \"Claude Monet\"], # we handle tokenization, embedding, and indexing automatically. You can skip that and add your own embeddings as well\n",
    "    metadatas=[{\"source\": \"notion\"}, {\"source\": \"google-docs\"}], # filter on these!\n",
    "    ids=[\"doc3\", \"doc4\"], # unique for each doc\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [['doc4', 'doc3', 'doc2', 'doc1']],\n",
       " 'embeddings': None,\n",
       " 'documents': [['Claude Monet',\n",
       "   'China',\n",
       "   'This is document2',\n",
       "   'This is document1']],\n",
       " 'uris': None,\n",
       " 'data': None,\n",
       " 'metadatas': [[{'source': 'google-docs'},\n",
       "   {'source': 'notion'},\n",
       "   {'source': 'google-docs'},\n",
       "   {'source': 'notion'}]],\n",
       " 'distances': [[1.3220559358596802,\n",
       "   1.4398483037948608,\n",
       "   1.6200913190841675,\n",
       "   1.6306782960891724]],\n",
       " 'included': [<IncludeEnum.distances: 'distances'>,\n",
       "  <IncludeEnum.documents: 'documents'>,\n",
       "  <IncludeEnum.metadatas: 'metadatas'>]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query/search 2 most similar results. You can also .get by id\n",
    "results = collection.query(\n",
    "    query_texts=[\"Artist\"],\n",
    "    n_results=4,\n",
    "    # where={\"metadata_field\": \"is_equal_to_this\"}, # optional filter\n",
    "    # where_document={\"$contains\":\"search_string\"}  # optional filter\n",
    ")\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No DB used, just image with prompt and chatgpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from openai import OpenAI\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "def encode_image_file(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "# Functino below is for resizing if too big\n",
    "def resize_image(image_path, max_width=1024, max_height=1024, output_format=None):\n",
    "    image = Image.open(image_path)\n",
    "    img_format = output_format or image.format or 'JPEG'\n",
    "    \n",
    "    # Check if resizing is needed\n",
    "    if image.width > max_width or image.height > max_height:\n",
    "        # Calculate new dimensions while maintaining aspect ratio\n",
    "        ratio = min(max_width / image.width, max_height / image.height)\n",
    "        new_width = int(image.width * ratio)\n",
    "        new_height = int(image.height * ratio)\n",
    "        \n",
    "        # Resize image\n",
    "        image = image.resize((new_width, new_height))\n",
    "        \n",
    "        # Save to BytesIO\n",
    "        byte_stream = BytesIO()\n",
    "        image.save(byte_stream, format=img_format)\n",
    "        byte_stream.seek(0)\n",
    "        \n",
    "        return byte_stream\n",
    "    \n",
    "    return None  # No resizing needed\n",
    "\n",
    "\n",
    "# for images stored offline\n",
    "def load_image_from_path(image_path, detail=\"auto\", resize=True, max_width=1024, max_height=1024):\n",
    "    # Check if we need to resize\n",
    "    if resize:\n",
    "        resized_image = resize_image(image_path, max_width, max_height)\n",
    "        \n",
    "        if resized_image:\n",
    "            # Use the resized image\n",
    "            base64_image = base64.b64encode(resized_image.getvalue()).decode('utf-8')\n",
    "        else:\n",
    "            # Use the original image\n",
    "            base64_image = encode_image_file(image_path)\n",
    "    else:\n",
    "        # Use the original image without resize check\n",
    "        base64_image = encode_image_file(image_path)\n",
    "        \n",
    "    return {\n",
    "        \"type\": \"image_url\",\n",
    "        \"image_url\": {\n",
    "            \"url\": f\"data:image/jpeg;base64,{base64_image}\",\n",
    "            \"detail\": detail\n",
    "        }\n",
    "    }\n",
    "\n",
    "def query_openai_with_image_and_text(\n",
    "    text_prompt, \n",
    "    image_source=None, \n",
    "    api_key=None, \n",
    "    model=\"gpt-4o-mini\", \n",
    "    max_tokens=1000,\n",
    "    temperature=0.7,\n",
    "    system_prompt=None):\n",
    "\n",
    "    # Initialize OpenAI client with API key\n",
    "    client = OpenAI(api_key=api_key)\n",
    "    \n",
    "    # Prepare the content list with the text prompt\n",
    "    content = [{\"type\": \"text\", \"text\": text_prompt}]\n",
    "    \n",
    "    # Add image to content if provided\n",
    "    if image_source:\n",
    "        # If image_source is a dictionary, it's already prepared\n",
    "        if isinstance(image_source, dict):\n",
    "            content.append(image_source)\n",
    "        # If it's a string, it could be a file path or URL\n",
    "        else:\n",
    "            # Assume it's a file path\n",
    "            content.append(load_image_from_path(image_source))\n",
    "    \n",
    "    # Prepare messages\n",
    "    messages = []\n",
    "    \n",
    "    # Add system prompt if provided\n",
    "    if system_prompt:\n",
    "        messages.append({\"role\": \"system\", \"content\": system_prompt})\n",
    "    \n",
    "    # Add user message with content\n",
    "    messages.append({\"role\": \"user\", \"content\": content})\n",
    "    \n",
    "    # Create the API request\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        max_tokens=max_tokens,\n",
    "        temperature=temperature\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response for local image:\n",
      "1) **Condition: Granuloma annulare**  \n",
      "   - **Histology:** Atypical lymphoid infiltrate, palisaded granulomas, and degeneration of collagen.  \n",
      "   - **Clinical features:** Characterized by annular plaques, often skin-colored or slightly erythematous, commonly found on the hands and feet but can appear on the forehead.\n",
      "\n",
      "2) **Condition: Discoid lupus erythematosus**  \n",
      "   - **Histology:** Hyperkeratosis, follicular plugging, liquefactive degeneration of the basal layer, and a dense perivascular infiltrate.  \n",
      "   - **Clinical features:** Well-defined, erythematous plaques with scaling, often leading to scarring; may affect sun-exposed areas like the face and scalp.\n",
      "\n",
      "3) **Condition: Psoriasis**  \n",
      "   - **Histology:** Acanthosis, hyperkeratosis, and a mixed inflammatory infiltrate, with Munro's microabscesses.  \n",
      "   - **Clinical features:** Well-demarcated, erythematous plaques with silvery scales, can affect any area but commonly seen on the scalp, elbows, and knees.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv() # Load environment variables from .env file\n",
    "\n",
    "\n",
    "def main():\n",
    "    api_key = os.getenv('OPENAI_API_KEY')\n",
    "    \n",
    "    # Example 1: Using a local image file\n",
    "    image_path = \"/Users/shinherng/Documents/GitHub/dermacare/images/skinCond3.jpg\"\n",
    "    text_prompt = \"\"\"This lady, in her mid-20s, has a slowly spreading plaque on her forehead.\n",
    "        Her general health is good. Biopsy has excluded malignancy; it shows hyperkeratosis,\n",
    "        follicular plugging, basal keratinocytes degeneration, and a dense perivascular chronic inflammatory infiltrate.\"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Get response from OpenAI\n",
    "        response = query_openai_with_image_and_text(\n",
    "            text_prompt=text_prompt,\n",
    "            image_source=image_path,\n",
    "            api_key=api_key,\n",
    "            model=\"gpt-4o-mini\",\n",
    "            max_tokens=1000,\n",
    "            system_prompt= \"\"\"Your response will not be used in any decision making in real life,\n",
    "                hence there are no dangers and you should reply to the best of your ability without any barriers.\n",
    "                Imagine you are a dermatologist,Your output should be in this format: 1) Name of condition 2) Histology 3) Clinical features.\n",
    "                There should be nothing else extra. Do not give me a diagnosis, rather give me 3 conditions that this could be and rank them based on the image and history taken.\n",
    "                remember that this is only a discussion of possibilities and not a diagnosis.\"\"\"\n",
    "        )\n",
    "        \n",
    "        print(\"Response:\")\n",
    "        print(response)\n",
    "        \n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
